{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import GPUtil\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar base de datos de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar conjunto de entraniento \n",
    "trainingData = pd.read_csv(r'S:\\Proyecto Epilepsia\\TTV\\Training.csv')  # Base da datos completa col = 'Sample', 'Target'\n",
    "X_train = trainingData['Sample']   # Asignar columna de samples a X\n",
    "y_train = trainingData['Target']   # Asignar columna de target a y \n",
    "\n",
    "# Cargar conjunto de testing\n",
    "testingData = pd.read_csv(r'S:\\Proyecto Epilepsia\\TTV\\Testing.csv')  # Base da datos completa col = 'Sample', 'Target'\n",
    "X_testing = testingData['Sample']   # Asignar columna de samples a X\n",
    "y_testing = testingData['Target']   # Asignar columna de target a y \n",
    "\n",
    "# Cargar conjunto de validation\n",
    "valData = pd.read_csv(r'S:\\Proyecto Epilepsia\\TTV\\Validation.csv')  # Base da datos completa col = 'Sample', 'Target'\n",
    "X_val = valData['Sample']   # Asignar columna de samples a X\n",
    "y_val = valData['Target']   # Asignar columna de target a y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a arrelos training \n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# Convertir a arrelos testing\n",
    "X_testing = X_testing.to_numpy()\n",
    "y_testing = y_testing.to_numpy()\n",
    "\n",
    "# Convertir a arrelos validation \n",
    "X_val = X_val.to_numpy()\n",
    "y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir transformaciones para base de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media y desviación estandar del conjunto de entrenamiento\n",
    "genMean = [0.2487, 0.2487, 0.2487]\n",
    "genSD = [0.2377, 0.2377, 0.2377]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformacion para la imagen \n",
    "traingTans = transforms.Compose([ transforms.RandomHorizontalFlip(p=0.5), # Hace un flip en el sentido horizontal \n",
    "                                  transforms.ToTensor(), # toma los valores iniciales y los escala a valores entre 0-1\n",
    "                                  transforms.Normalize(genMean, genSD)\n",
    "                                  ],\n",
    "                               ) \n",
    "\n",
    "testTrans = transforms.Compose([ transforms.ToTensor(), # toma los valores iniciales y los escala a valores entre 0-1\n",
    "                                 transforms.Normalize(genMean, genSD)\n",
    "                                  ],\n",
    "                               ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Cargar la imagen y convertir a RGB\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muestras de training\n",
    "trainSample = CustomImageDataset(image_paths=X_train,targets=y_train,transform = traingTans)\n",
    "\n",
    "# Muestras testing\n",
    "testSample = CustomImageDataset(image_paths=X_testing,targets=y_testing,transform = testTrans)\n",
    "\n",
    "# Muestras val \n",
    "valSample = CustomImageDataset(image_paths=X_val,targets=y_val,transform = testTrans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar data loader\n",
    "batch = 32\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainSample, batch_size=batch,shuffle=True)\n",
    "testingLoader = DataLoader(dataset=testSample, batch_size=batch,shuffle=True)\n",
    "valLoader = DataLoader(dataset=valSample, batch_size=batch,shuffle=True)\n",
    "\n",
    "# DataLoader -> Facilita la carda de datos para entrenamiento y evaluación de modelos\n",
    "# Carga los datos en mini-batches para tener fragmentos manejables y actualizar los pesos\n",
    "# Genera aleatoridad en los datos para ayudar a la generalización de los datos\n",
    "# Proporiona interfaz iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar imagenes de data iter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainLoader)\n",
    "\n",
    "img,lb = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.2486, 0.2486, 0.2486])\n",
    "        std = np.array([0.2377, 0.2377, 0.2377])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0].shape)\n",
    "imgTrans = img[0].numpy().transpose((1, 2, 0)) # transpone las dimensiones del arrelo en este caso incialmente se tiene (3,256,256) -> (256,256,3)\n",
    "print(imgTrans.shape)\n",
    "plt.imshow(imgTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img[0])\n",
    "imshow(img[0],normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de dispositivos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.is_available()\n",
    "\n",
    "if not device:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 0, Name: NVIDIA GeForce RTX 4070 Laptop GPU, Load: 15.0%, Memory Free: 7827.0MB, Memory Used: 122.0MB, Memory Total: 8188.0MB, Temperature: 47.0 °C\n"
     ]
    }
   ],
   "source": [
    "# Tipo de GPU donde se está entrenando la red\n",
    "gpus = GPUtil.getGPUs()\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"ID: {gpu.id}, Name: {gpu.name}, Load: {gpu.load*100}%, Memory Free: {gpu.memoryFree}MB, Memory Used: {gpu.memoryUsed}MB, Memory Total: {gpu.memoryTotal}MB, Temperature: {gpu.temperature} °C\")\n",
    "else:\n",
    "    print(\"No GPUs available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura CCN (3 Capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# img - entrada -> 256\n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNet, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=3, padding=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(10)        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20,out_channels=30,kernel_size=3, padding=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(30)\n",
    "        \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Multilayer\n",
    "        self.fc1 = nn.Linear(30*32*32,5000)  # 16*16 es por la redución debido a la capa de pooling \n",
    "        self.fc2 = nn.Linear(5000,500)\n",
    "        self.fc3 = nn.Linear(500,2) \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 256*256 -> 128*128\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 128*128 -> 64*64\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 64*64 -> 32*32 \n",
    "        \n",
    "        x = x.view(-1, 30 * 32 * 32)\n",
    "        # Capa de dropout\n",
    "        x = self.dropout(x)\n",
    "        # primer capa fully connected \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Capa dropout \n",
    "        x = self.dropout(x)\n",
    "        # Segunda capa fully connected \n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Capa dropout\n",
    "        x = self.dropout(x)\n",
    "        # Tercer capa fully connected \n",
    "        x = self.fc3(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura de Red Neuronal (4 capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# img - entrada -> 256\n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNet, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=3, padding=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(10)        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20,out_channels=30,kernel_size=3, padding=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(30)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=30,out_channels=40,kernel_size=3, padding=1, stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Multilayer\n",
    "        self.fc1 = nn.Linear(40*16*16,5000)  # 16*16 es por la redución debido a la capa de pooling \n",
    "        self.fc2 = nn.Linear(5000,500)\n",
    "        self.fc3 = nn.Linear(500,2) \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 256*256 -> 128*128\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 128*128 -> 64*64\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(F.relu(x)) # debido a la capa de pooling se reduce la dim de 64*64 -> 32*32 \n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(F.relu(x))  # debido a la capa de pooling se reduce la dim de 32*32 -> 16*16 \n",
    "        \n",
    "        x = x.view(-1, 40 * 16 * 16)\n",
    "        # Capa de dropout\n",
    "        x = self.dropout(x)\n",
    "        # primer capa fully connected \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Capa dropout \n",
    "        x = self.dropout(x)\n",
    "        # Segunda capa fully connected \n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Capa dropout\n",
    "        x = self.dropout(x)\n",
    "        # Tercer capa fully connected \n",
    "        x = self.fc3(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de entrenamiento y definición de red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNet(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(20, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(30, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=10240, out_features=5000, bias=True)\n",
       "  (fc2): Linear(in_features=5000, out_features=500, bias=True)\n",
       "  (fc3): Linear(in_features=500, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.35, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move tensors to GPU if CUDA is available\n",
    "if device:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterio, optimizador y función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# update training loss\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mdata\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m######################    \u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# validate the model #\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in trainLoader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if device:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valLoader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if device:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainLoader.sampler)\n",
    "    valid_loss = valid_loss/len(valLoader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_CNN_SGD_100.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 3 capas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_CNN_EL.pt'))  # Cargar datos del modelo de 3 capas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track test loss\n",
    "# test_loss = 0.0\n",
    "TP = 0.0\n",
    "TN = 0.0\n",
    "FP = 0.0\n",
    "FN = 0.0\n",
    "posFR = 1\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in testingLoader:\n",
    "    if device:\n",
    "        data, target = data.cuda(), target.cuda()  # Enviar tensores a cuda\n",
    "    \n",
    "    output = model(data)  # Da la salida en valores calculados por la red \n",
    "    \n",
    "    loss = criterion(output, target)  # Criterio de pérdida que emplea CrossEntropyLoss\n",
    "     \n",
    "    # test_loss += loss.item()*data.size(0)  # Sumatoria de perdidas \n",
    "    \n",
    "    _, pred = torch.max(output, 1)   # Regresa el índice del arrego de salida con el valor más alto  para determinar la clase a la que pertenece \n",
    "    \n",
    "    #Imprimir target y predicción     \n",
    "    # print('Preiction: ', pred)\n",
    "    # print('Target: ', target)\n",
    "    \n",
    "    ## Statics calculation\n",
    "    TP += torch.sum((target == posFR) & (pred == posFR)).item()\n",
    "    # print(TP)\n",
    "    TN += torch.sum((target != posFR) & (pred != posFR)).item()\n",
    "    # print(TN)\n",
    "    FP += torch.sum((target != posFR) & (pred == posFR)).item()\n",
    "    # print(FP)\n",
    "    FN += torch.sum((target == posFR) & (pred != posFR)).item()\n",
    "    # print(FN)\n",
    "\n",
    "# test_loss = test_loss/len(testingLoader.dataset)\n",
    "# print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de mediads estadisticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  346.0\n",
      "TN:  8232.0\n",
      "FP:  175.0\n",
      "FN:  121.0\n"
     ]
    }
   ],
   "source": [
    "print('TP: ',TP)\n",
    "print('TN: ',TN)\n",
    "print('FP: ',FP)\n",
    "print('FN: ',FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.08993576017131\n",
      "97.91840133222316\n",
      "66.41074856046065\n",
      "96.66441289159341\n"
     ]
    }
   ],
   "source": [
    "## Sensitividad:\n",
    "Sen = (TP)/(TP+FN)*100\n",
    "print(Sen)\n",
    "Spc = (TN)/(TN+FP)*100\n",
    "print(Spc)\n",
    "Pres = (TP)/(TP+FP)*100\n",
    "print(Pres)\n",
    "Acc = (TP+TN)/(TP+FN+TN+FP)*100 \n",
    "print(Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
